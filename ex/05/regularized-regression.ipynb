{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E\\lbrack B_{r}\\rbrack\\  = \\ S_{T}^{- 1}S\\beta^{*}$$\n",
    "\n",
    "Where $S\\  = \\ X^{T}X$ , $S_{T}\\  = \\ X^{T}X\\  + \\ \\tau I$\n",
    "\n",
    "$$X^{T}\\  = \\ V\\lambda U^{t}$$\n",
    "\n",
    "$$X\\  = \\ U\\lambda V^{T}$$\n",
    "\n",
    "$$X^{T}X\\  = \\ V\\lambda^{2}V^{T}$$\n",
    "\n",
    "For, $E\\lbrack\\beta_{r}\\rbrack\\  = \\ S_{T}^{- 1}S\\beta^{*}$\n",
    "\n",
    "= ${(X^{T}X\\  + \\ \\tau I)}^{- 1}\\ (X^{T}X)\\beta^{*}$\n",
    "\n",
    "= $V{(\\lambda^{2} + \\tau I)}^{- 1}\\ V^{T}V\\lambda^{2}U^{T}\\beta^{*}$\n",
    "\n",
    "= $V{(\\lambda^{2} + \\tau I)}^{- 1}\\ \\lambda^{2}U^{T}\\beta^{*}$\n",
    "\n",
    "= $V\\lambda^{|}U^{T}\\beta^{*}$\n",
    "\n",
    "= ${(X^{T}X\\  + \\ \\tau I)}^{- 1}X^{T}X\\beta$\n",
    "\n",
    "= $S_{T}^{- 1}S\\beta^{*}$\n",
    "\n",
    "For $cov\\lbrack\\beta_{r}\\rbrack\\  = \\ S_{T}^{- 1}SS_{T}^{- 1}\\sigma^{2}$\n",
    "\n",
    "=\n",
    "${(X^{T}X\\  + \\ \\tau I)}^{- 1}\\ (X^{T}X)\\ {(X^{T}X\\  + \\ \\tau I)}^{- 1}\\ \\sigma^{2}$\n",
    "\n",
    "=\n",
    "$V{(\\lambda^{2} + \\tau I)}^{- 1}\\ V^{T}V\\lambda^{2}U^{T}(V{(\\lambda^{2} + \\tau I)}^{- 1})\\ V^{T}$\n",
    "\n",
    "=\n",
    "$V{(\\lambda^{2} + \\tau I)}^{- 1}\\ \\lambda^{2}U^{T}(V{(\\lambda^{2} + \\tau I)}^{- 1})\\ V^{T}$\n",
    "\n",
    "=\n",
    "$V\\lambda^{|}U^{T}\\ V\\lambda^{|}U^{T}V{\\lambda^{2}}^{|}U^{T}\\sigma^{2}$\n",
    "\n",
    "= $S_{T}^{- 1}SS_{T}^{- 1}\\sigma^{2}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filters\n",
    "import numpy as np\n",
    "from os import path\n",
    "from scipy.sparse import coo_matrix, csc_matrix\n",
    "from scipy.ndimage import filters\n",
    "from scipy.sparse.linalg import lsqr\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 automatic feature selection for LDA as regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49225\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "\n",
    "data_path = \"../04/\"\n",
    "M, alphas, y = 195, np.load(path.join(data_path, \"hs_tomography/alphas_195.npy\")), np.load(path.join(data_path, \"./hs_tomography/y_195.npy\"))\n",
    "Np = 275\n",
    "# append D zeros to y\n",
    "D = np.square(M)\n",
    "y_ = np.append(y, np.zeros((1, D)))\n",
    "print(y.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_X(M, alphas, Np = None):\n",
    "    D = M*M\n",
    "    # define sensor size\n",
    "    if Np is None:\n",
    "        Np = int(np.ceil(np.sqrt(2) * M))\n",
    "        if Np % 2 == 0: Np += 1\n",
    "    # number of angles\n",
    "    No = len(alphas)\n",
    "\n",
    "    # flattened output coordinates\n",
    "    j = np.mgrid[0:D].astype(np.int32)\n",
    "    # coordinate matrix for the output pixels\n",
    "    M2 = (M-1) / 2\n",
    "    grid = np.mgrid[-M2:M-M2,-M2:M-M2].swapaxes(1,2).reshape(2,D)\n",
    "\n",
    "    # collect indices and corresponding values for all iterations\n",
    "    i_indices = []\n",
    "    j_indices = []\n",
    "    weights = []\n",
    "\n",
    "    for k, alpha in enumerate(alphas):\n",
    "        # convert angle and prepare projection vector\n",
    "        alph_rad = np.radians(alpha)\n",
    "        proj_vec = np.array([np.cos(alph_rad), -np.sin(alph_rad)])\n",
    "        # project coordinates\n",
    "        proj = np.dot(proj_vec, grid) + Np // 2\n",
    "        # compute sensor indices and weights below the projected points\n",
    "        i = np.floor(proj)\n",
    "        w = (i+1) - proj\n",
    "        # make sure rays falling outside the sensor are not counted\n",
    "        clip = np.logical_and(0 <= i, i < Np-1)\n",
    "        i_indices.append((i + k*Np)[clip])\n",
    "        j_indices.append(j[clip])\n",
    "        weights.append(w[clip])\n",
    "        # compute sensor indices and weights above the projected points\n",
    "        w = proj - i\n",
    "        i_indices.append((i+1 + k*Np)[clip])\n",
    "        j_indices.append(j[clip])\n",
    "        weights.append(w[clip])\n",
    "\n",
    "    # construct matrix X\n",
    "    i = np.concatenate(i_indices).astype(np.int32)\n",
    "    j = np.concatenate(j_indices).astype(np.int32)\n",
    "    w = np.concatenate(weights)\n",
    "    X = coo_matrix((w, (i,j)), shape = (No*Np, D), dtype = np.float32)\n",
    "    return X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Implement Orthogonal Matching Pursuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def omp_regression(X, y, T):\n",
    "    N=X.shape[0]\n",
    "    D=X.shape[1]\n",
    "    \n",
    "    A_0=[]\n",
    "    B_0=list(range(0,D))\n",
    "    r=y.copy()\n",
    "    \n",
    "    beta_t_Hat=[]\n",
    "    X_t_B=X.copy()\n",
    "    \n",
    "    for t in range(1,T+1):\n",
    "        j_vec=np.linalg.norm(np.transpose(X)*r,axis=1)\n",
    "        j_test=np.sort(j_vec)[::-1]\n",
    "        for test in j_test:\n",
    "            vector_to_check = np.where(j_vec==test)\n",
    "            if(vector_to_check[0].shape[0]==1):\n",
    "                if vector_to_check[0] in B_0:\n",
    "                    j=np.where(j_vec==test)[0]\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                found_j=-1\n",
    "                for possible_j in vector_to_check[0]:\n",
    "                    if possible_j in B_0:\n",
    "                        found_j=possible_j\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "                if found_j==-1:\n",
    "                    continue\n",
    "                else:\n",
    "                    j=found_j\n",
    "                    break\n",
    "                        \n",
    "        j_t=B_0.pop(B_0.index(j))\n",
    "        A_0.append(j_t)\n",
    "        X_t=X[:,A_0]\n",
    "        #X_t_B=X[:,B_0]\n",
    "        beta_t,residuals,rank,s=np.linalg.lstsq(X_t,y,rcond=None)\n",
    "        r=residuals\n",
    "        beta_t_hat=np.zeros(D)\n",
    "        beta_t_hat[A_0]=beta_t\n",
    "        beta_t_Hat.append(beta_t_hat)\n",
    "    return beta_t_Hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def omp_regression(X, y ,T=99):\n",
    "    print(\"X:\",X.shape,\" y: \", y.shape, \"T:\",T)\n",
    "    A, B, r, R = np.zeros(T),np.arange(X.shape[1]), y, np.zeros((X.shape[0],T))\n",
    "    print(A.shape,B.shape,R.shape)\n",
    "    X = csc_matrix(X)\n",
    "    print(X.shape)\n",
    "    for t in range(T):\n",
    "        j = np.argmax(np.abs(X.T[B]*r))\n",
    "        A[t] = B[j]\n",
    "        B = np.delete(B,j)\n",
    "        Xt = X[:,A]\n",
    "        βt = lsqr(Xt,y)[0]\n",
    "        R[t] = βt\n",
    "        r = y - Xt*βt\n",
    "    return R"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Classification wtih sparse LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data():\n",
    "    # read and prepare the digits data\n",
    "    digits = load_digits()\n",
    "\n",
    "    data = digits['data']\n",
    "    target = digits['target']\n",
    "\n",
    "    #filter targets and data - to only contain datasets about 1 and 7 \n",
    "    data_1   =   data[target == 1]\n",
    "    target_1 = target[target == 1]\n",
    "    \n",
    "    data_7   =   data[target == 7]\n",
    "    target_7 = target[target == 7]\n",
    "    target_7[:] = -1\n",
    "    \n",
    "    data = np.append(data_1, data_7).reshape(-1,64)\n",
    "    target = np.append(target_1, target_7)\n",
    "    \n",
    "    return data,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_error(results,T,x_test,y_test):\n",
    "    #print(f\"x_test: {x_test.shape}, T: {T}, y_test: {y_test.shape}, results: {results.shape}\")\n",
    "    results_t_i = np.sum(x_test[:]*results[T-1],axis=1)\n",
    "    results_t_i[results_t_i>=0] =  1\n",
    "    results_t_i[results_t_i<0]  = -1\n",
    "    err_t_i = np.where(results_t_i!=y_test)[0].shape[0] / y_test.shape[0]\n",
    "    print('error rate for T='+str(T)+': '+str(err_t_i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (252, 64)  y:  (252,) T: 54\n",
      "(54,) (64,) (252, 54)\n",
      "(252, 64)\n",
      "(252, 54)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (109,64) (54,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(results\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m \u001b[39m#lets now determine the error rates\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m#therefore we will use a classifier which computes the results and the error rates\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m determine_error(results,\u001b[39m1\u001b[39;49m ,x_test,y_test)\n\u001b[1;32m      9\u001b[0m determine_error(results,\u001b[39m2\u001b[39m ,x_test,y_test)\n\u001b[1;32m     10\u001b[0m determine_error(results,\u001b[39m4\u001b[39m ,x_test,y_test)\n",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m, in \u001b[0;36mdetermine_error\u001b[0;34m(results, T, x_test, y_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetermine_error\u001b[39m(results,T,x_test,y_test):\n\u001b[1;32m      2\u001b[0m     \u001b[39m#print(f\"x_test: {x_test.shape}, T: {T}, y_test: {y_test.shape}, results: {results.shape}\")\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     results_t_i \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(x_test[:]\u001b[39m*\u001b[39;49mresults[T\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m     results_t_i[results_t_i\u001b[39m>\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m  \u001b[39m1\u001b[39m\n\u001b[1;32m      5\u001b[0m     results_t_i[results_t_i\u001b[39m<\u001b[39m\u001b[39m0\u001b[39m]  \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (109,64) (54,) "
     ]
    }
   ],
   "source": [
    "X,y = load_and_prepare_data()\n",
    "x_training, x_test, y_training, y_test = train_test_split(X, y,test_size=0.3,random_state=42)\n",
    "results = omp_regression(x_training,y_training,54)\n",
    "print(results[0].shape)\n",
    "#lets now determine the error rates\n",
    "#therefore we will use a classifier which computes the results and the error rates\n",
    "\n",
    "determine_error(results,1 ,x_test,y_test)\n",
    "determine_error(results,2 ,x_test,y_test)\n",
    "determine_error(results,4 ,x_test,y_test)\n",
    "determine_error(results,8 ,x_test,y_test)\n",
    "determine_error(results,12,x_test,y_test)\n",
    "determine_error(results,16,x_test,y_test)\n",
    "determine_error(results,32,x_test,y_test)\n",
    "determine_error(results,48,x_test,y_test)\n",
    "\n",
    "print(\"Starting from T = 16 the error is no longer decreased\")\n",
    "\n",
    "#we want to print a 8 by 8 picture which is all white but the pixels which are turned on are black in increasing \n",
    "#intensity shwoing the pixels which are most important in highest identity\n",
    "importance = np.ones(64)\n",
    "tendencie  = np.ones(64) \n",
    "\n",
    "#we now nee to find the order in which the pixels have been tunred on\n",
    "helper = np.zeros(64)\n",
    "indecies_used=[]\n",
    "for i in range(0,16):\n",
    "    indecies_changed = np.where(helper!=results[i])[0]\n",
    "    index_added = -1\n",
    "    for possible_i in indecies_changed:\n",
    "        if possible_i in indecies_used:\n",
    "            continue\n",
    "        else:\n",
    "            index_added = possible_i\n",
    "            indecies_used.append(possible_i)\n",
    "            break\n",
    "    \n",
    "    helper = results[i]\n",
    "    importance[index_added] = i * (1/32)\n",
    "    if results[i][index_added]<0:\n",
    "        tendencie[index_added] = 0.5\n",
    "    else:\n",
    "        tendencie[index_added] = 0\n",
    "\n",
    "print('----------------------------')\n",
    "print(\"We used the following pixels:\")  \n",
    "print(indecies_used)\n",
    "print('----------------------------')\n",
    "        \n",
    "importance = importance.reshape(8,8)\n",
    "tendencie  = tendencie.reshape(8,8)\n",
    "\n",
    "fig = plt.figure()\n",
    "imgplot = plt.imshow(importance,cmap=\"hot\")\n",
    "plt.title('Heatmap for T=16')\n",
    "\n",
    "##next up we anna show if those pixels point towards one or two\n",
    "fig = plt.figure()\n",
    "imgplot = plt.imshow(tendencie,cmap=\"hot\")\n",
    "plt.title('Tendendcies for T=16:[orange=1;black=7]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
